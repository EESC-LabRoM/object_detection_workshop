{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import argparse\n",
    "import logging\n",
    "import logging.config\n",
    "from pathlib import Path\n",
    "from utils.json import get_json_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def copy_images(images, src_dir, dest_dir):\n",
    "    \"\"\"\n",
    "    Copy selected images to a specified directory.\n",
    "    \"\"\"\n",
    "    for image in images:\n",
    "        try:\n",
    "            src_path = Path(src_dir) / image['file_name']\n",
    "            dest_path = Path(dest_dir) / src_path.name\n",
    "            shutil.copy(src_path, dest_path)\n",
    "            logger.info(f\"Successfully copied {src_path} to {dest_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to copy {src_path} to {dest_path}: {e}\")\n",
    "\n",
    "def split_dataset(images_dir, labels_json_path, output_dir, train_ratio=0.75, val_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Splits a COCO dataset into training, validation, and testing sets based on given ratios.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"Loading COCO annotations...\")\n",
    "        coco_data = get_json_from_file(labels_json_path)\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"File not found: {labels_json_path}\")\n",
    "        return\n",
    "    except json.JSONDecodeError:\n",
    "        logger.error(f\"Invalid JSON in file: {labels_json_path}\")\n",
    "        return\n",
    "\n",
    "    images_dir = Path(images_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "\n",
    "    if not images_dir.exists():\n",
    "        logger.error(f\"Images directory does not exist: {images_dir}\")\n",
    "        return\n",
    "\n",
    "    # Extract image and annotation details\n",
    "    images = coco_data.get('images', [])\n",
    "    annotations = coco_data.get('annotations', [])\n",
    "\n",
    "    # Validate ratios\n",
    "    if not (0 < train_ratio < 1 and 0 <= val_ratio < 1 and train_ratio + val_ratio <= 1):\n",
    "        logger.error(\"Invalid training/validation ratios.\")\n",
    "        return\n",
    "\n",
    "    random.shuffle(images)\n",
    "    total_images = len(images)\n",
    "    train_end = int(total_images * train_ratio)\n",
    "    val_end = train_end + int(total_images * val_ratio)\n",
    "\n",
    "    train_images = images[:train_end]\n",
    "    val_images = images[train_end:val_end]\n",
    "    test_images = images[val_end:]\n",
    "\n",
    "    def filter_annotations(images_set):\n",
    "        image_ids = {image['id'] for image in images_set}\n",
    "        return [annotation for annotation in annotations if annotation['image_id'] in image_ids]\n",
    "\n",
    "    def create_coco_subset(images, annotations):\n",
    "        return {\n",
    "            'images': images,\n",
    "            'annotations': annotations,\n",
    "            'categories': coco_data['categories']\n",
    "        }\n",
    "\n",
    "    for type, images_set in zip([\"train\", \"val\", \"test\"], [train_images, val_images, test_images]):\n",
    "        try:\n",
    "            images_output_path = output_dir / \"images\" / type\n",
    "            images_output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            labels_output_path = output_dir / \"labels\" / type\n",
    "            labels_output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            copy_images(images_set, images_dir, images_output_path)\n",
    "\n",
    "            coco_file = create_coco_subset(images_set, filter_annotations(images_set))\n",
    "            with open(labels_output_path / \"coco.json\", 'w') as file:\n",
    "                json.dump(coco_file, file, indent=4)\n",
    "            logger.info(f\"Dataset for {type} saved successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to process data for {type}: {e}\")\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Split COCO dataset into training, validation, and testing sets.\")\n",
    "    parser.add_argument(\"images_dir\", help=\"Path to the input directory containing images.\")\n",
    "    parser.add_argument(\"coco_json_path\", help=\"Path to the COCO JSON file containing annotations.\")\n",
    "    parser.add_argument(\"output_dir\", help=\"Path to the root output directory for training, validation, and testing sets.\")\n",
    "    parser.add_argument(\"--train_ratio\", type=float, default=0.75, help=\"Proportion of images for training (default: 0.75)\")\n",
    "    parser.add_argument(\"--val_ratio\", type=float, default=0.1, help=\"Proportion of images for validation (default: 0.1)\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    split_dataset(args.images_dir, args.coco_json_path, args.output_dir, args.train_ratio, args.val_ratio)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
