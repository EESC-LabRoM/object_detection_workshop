{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas Utilizadas\n",
    "\n",
    "<div class=\"text-justify\">\n",
    " \n",
    "- **Json:** A biblioteca `json` fornece uma maneira fácil de codificar e decodificar dados no formato JSON (JavaScript Object Notation) em Python. Ela permite converter objetos Python em strings JSON e vice-versa. É amplamente utilizada para trocar dados entre clientes e servidores.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"text-justify\">\n",
    "\n",
    "- **Shutil:** A biblioteca `shutil` oferece várias operações de alto nível em arquivos e coleções de arquivos. Ela permite copiar, mover, renomear e remover arquivos e diretórios. É útil para gerenciar arquivos de forma programática.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"text-justify\">\n",
    "\n",
    "- **Random:** A biblioteca `random` gera números pseudo-aleatórios e permite realizar operações como escolher elementos aleatórios de uma lista, embaralhar sequências e gerar amostras aleatórias. Ela é frequentemente usada em simulações e jogos.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"text-justify\">\n",
    "\n",
    "- **Logging:** A biblioteca `logging` fornece um sistema flexível para registrar eventos de software, mensagens de erro e outros tipos de logs. Ela permite registrar mensagens em diferentes níveis de severidade e enviar esses registros para diversos destinos, como arquivos e consoles.\n",
    "\n",
    "  - **logging.config:** A biblioteca `logging.config` estende a funcionalidade de `logging` permitindo a configuração de registros por meio de arquivos de configuração. Ela facilita a definição de configurações complexas de registro sem a necessidade de código adicional.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"text-justify\">\n",
    "\n",
    "- **Sys:** A biblioteca `sys` fornece acesso a algumas variáveis e funções interativas do interpretador Python. Ela permite manipular o ambiente de execução, como argumentos de linha de comando e fluxo de entrada/saída padrão. É útil para scripts que interagem diretamente com o sistema.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"text-justify\">\n",
    "\n",
    "- **Pathlib:** A biblioteca `pathlib` fornece classes para manipulação de caminhos do sistema de arquivos de forma orientada a objetos. Ela facilita operações de leitura, escrita e navegação em diretórios de maneira intuitiva. É uma alternativa moderna à biblioteca `os.path`.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import argparse\n",
    "import logging\n",
    "import logging.config\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação do Dataset\n",
    "\n",
    "As funções a seguir separam o dataset que temos em Treinamento, Validação e Teste. Para isso, temos as seguintes funções:\n",
    "\n",
    "- **split_dataset**: Divide um conjunto de dados COCO em conjuntos de treinamento, validação e teste com base em proporções definidas. Carrega as anotações a partir de um arquivo JSON, valida as proporções fornecidas, embaralha aleatoriamente as imagens e as distribui conforme as proporções especificadas. Além disso, cria subconjuntos COCO para cada um dos conjuntos de dados (treinamento, validação, teste) e salva os arquivos JSON correspondentes em diretórios específicos, mantendo a estrutura de anotações e categorias.\n",
    "\n",
    "- **copy_images**: Copia as imagens selecionadas para um diretório especificado. Para cada imagem, a função constrói o caminho completo de origem e destino, realiza a cópia da imagem e registra logs de sucesso ou erro durante o processo, garantindo que todas as imagens necessárias sejam corretamente transferidas para os diretórios de treinamento, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração básica do logging para capturar logs de informação\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def copy_images(images, src_dir, dest_dir):\n",
    "    \"\"\"\n",
    "    Copia as imagens selecionadas para um diretório especificado.\n",
    "    \n",
    "    Args:\n",
    "        images (list): Lista de dicionários contendo informações das imagens.\n",
    "        src_dir (str): Diretório de origem das imagens.\n",
    "        dest_dir (str): Diretório de destino das imagens.\n",
    "    \"\"\"\n",
    "    for image in images:\n",
    "        try:\n",
    "            # Construção do caminho completo da imagem de origem\n",
    "            src_path = Path(src_dir) / image['file_name']\n",
    "            # Construção do caminho completo da imagem de destino\n",
    "            dest_path = Path(dest_dir) / src_path.name\n",
    "            # Copia a imagem do diretório de origem para o diretório de destino\n",
    "            shutil.copy(src_path, dest_path)\n",
    "            # Log de sucesso na cópia da imagem\n",
    "            logger.info(f\"Copiado com sucesso de {src_path} para {dest_path}\")\n",
    "        except Exception as e:\n",
    "            # Log de erro se a cópia falhar\n",
    "            logger.error(f\"Falha ao copiar {src_path} para {dest_path}: {e}\")\n",
    "\n",
    "def split_dataset(images_dir, labels_json_path, output_dir, train_ratio=0.75, val_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Divide um conjunto de dados COCO em conjuntos de treinamento, validação e teste com base em determinadas proporções.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): Diretório contendo as imagens.\n",
    "        labels_json_path (str): Caminho do arquivo JSON contendo as anotações COCO.\n",
    "        output_dir (str): Diretório onde os dados divididos serão armazenados.\n",
    "        train_ratio (float): Proporção do conjunto de treinamento.\n",
    "        val_ratio (float): Proporção do conjunto de validação.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Log informando o início do carregamento das anotações\n",
    "        logger.info(\"Carregando as anotações feitas em COCO...\")\n",
    "        # Carregamento das anotações COCO a partir do arquivo JSON\n",
    "        with open(labels_json_path, 'r') as f:\n",
    "            coco_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        # Log de erro se o arquivo JSON não for encontrado\n",
    "        logger.error(f\"Arquivo não encontrado: {labels_json_path}\")\n",
    "        return\n",
    "    except json.JSONDecodeError:\n",
    "        # Log de erro se o arquivo JSON estiver inválido\n",
    "        logger.error(f\"Arquivo JSON Invalido: {labels_json_path}\")\n",
    "        return\n",
    "\n",
    "    # Convertendo caminhos de diretórios para objetos Path\n",
    "    images_dir = Path(images_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "\n",
    "    if not images_dir.exists():\n",
    "        # Log de erro se o diretório das imagens não existir\n",
    "        logger.error(f\"Diretorio das Imagens não existe: {images_dir}\")\n",
    "        return\n",
    "\n",
    "    # Extração dos detalhes das imagens e anotações do conjunto de dados COCO\n",
    "    images = coco_data.get('images', [])\n",
    "    annotations = coco_data.get('annotations', [])\n",
    "\n",
    "    # Validação das proporções de treinamento e validação\n",
    "    if not (0 < train_ratio < 1 and 0 <= val_ratio < 1 and train_ratio + val_ratio <= 1):\n",
    "        # Log de erro se as proporções forem inválidas\n",
    "        logger.error(\"Proporções de treinamento/validação invalidas.\")\n",
    "        return\n",
    "\n",
    "    # Embaralhamento aleatório das imagens\n",
    "    random.shuffle(images)\n",
    "    total_images = len(images)\n",
    "    # Cálculo do índice final do conjunto de treinamento\n",
    "    train_end = int(total_images * train_ratio)\n",
    "    # Cálculo do índice final do conjunto de validação\n",
    "    val_end = train_end + int(total_images * val_ratio)\n",
    "\n",
    "    # Divisão das imagens em conjuntos de treinamento, validação e teste\n",
    "    train_images = images[:train_end]\n",
    "    val_images = images[train_end:val_end]\n",
    "    test_images = images[val_end:]\n",
    "\n",
    "    def filter_annotations(images_set):\n",
    "        \"\"\"\n",
    "        Filtra as anotações para corresponder ao conjunto de imagens fornecido.\n",
    "        \n",
    "        Args:\n",
    "            images_set (list): Lista de imagens para filtrar as anotações.\n",
    "            \n",
    "        Returns:\n",
    "            list: Lista de anotações filtradas.\n",
    "        \"\"\"\n",
    "        image_ids = {image['id'] for image in images_set}\n",
    "        return [annotation for annotation in annotations if annotation['image_id'] in image_ids]\n",
    "\n",
    "    def create_coco_subset(images, annotations):\n",
    "        \"\"\"\n",
    "        Cria um subconjunto COCO com as imagens e anotações fornecidas.\n",
    "        \n",
    "        Args:\n",
    "            images (list): Lista de imagens.\n",
    "            annotations (list): Lista de anotações.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Subconjunto COCO contendo imagens, anotações e categorias.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'images': images,\n",
    "            'annotations': annotations,\n",
    "            'categories': coco_data['categories']\n",
    "        }\n",
    "\n",
    "    # Iteração sobre os tipos de conjuntos de dados (treinamento, validação, teste)\n",
    "    for type, images_set in zip([\"train\", \"val\", \"test\"], [train_images, val_images, test_images]):\n",
    "        try:\n",
    "            # Criação do caminho de saída para as imagens\n",
    "            images_output_path = output_dir / \"images\" / type\n",
    "            images_output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Criação do caminho de saída para as anotações\n",
    "            labels_output_path = output_dir / \"labels\" / type\n",
    "            labels_output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Copia das imagens para o diretório de saída correspondente\n",
    "            copy_images(images_set, images_dir, images_output_path)\n",
    "\n",
    "            # Criação do arquivo JSON COCO para o conjunto de dados atual\n",
    "            coco_file = create_coco_subset(images_set, filter_annotations(images_set))\n",
    "            with open(labels_output_path / \"coco.json\", 'w') as file:\n",
    "                json.dump(coco_file, file, indent=4)\n",
    "            # Log de sucesso na criação do conjunto de dados\n",
    "            logger.info(f\"Conjunto de dados para {type} salvo com sucesso.\")\n",
    "        except Exception as e:\n",
    "            # Log de erro se houver falha no processamento do conjunto de dados\n",
    "            logger.error(f\"Falha ao processar dados para {type}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executando a Separação do Dataset\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    " \n",
    "- **origin**: Define o caminho para a pasta mãe, onde o diretório principal do workshop está localizado.\n",
    "\n",
    "- **images_dir**: Especifica o caminho para a pasta que contém as imagens do dataset.\n",
    "\n",
    "- **coco_json_path**: Aponta para o arquivo JSON que contém as anotações COCO do dataset.\n",
    "\n",
    "- **output_dir**: Indica o caminho para a pasta onde os dados separados serão armazenados.\n",
    "\n",
    "- **train_ratio**: Define a proporção de dados que serão utilizados para treinamento (neste caso, 75%).\n",
    "\n",
    "- **val_ratio**: Define a proporção de dados que serão utilizados para validação (neste caso, 10%).\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: justify;\"> <br>\n",
    "\n",
    "Ao chamar a função `split_dataset` com os caminhos e proporções definidos, o dataset será dividido em três conjuntos: <br>\n",
    "\n",
    "- **Treinamento**: 75% dos dados\n",
    "\n",
    "- **Validação**: 10% dos dados\n",
    "\n",
    "- **Teste**: O restante dos dados (15%)\n",
    "\n",
    "A função não só realiza a divisão das imagens, mas também copia as imagens para os diretórios apropriados e gera arquivos JSON COCO correspondentes para cada subconjunto. Isso garante que os dados estejam prontos para serem usados em treinamentos e avaliações de modelos de detecção de objetos.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para a pasta mãe, object_detection_workshop\n",
    "origin = Path.cwd().parent\n",
    "\n",
    "# Caminho para a pasta com as imagens do dataset\n",
    "images_dir = origin / \"Dados/Dataset/images\"\n",
    "\n",
    "# Caminho para a pasta do .json com as anotações do dataset\n",
    "coco_json_path = origin / \"Dados/Dataset/annotations/instances_default.json\"\n",
    "\n",
    "# Caminho para a pasta com os dados de saída\n",
    "output_dir = origin / \"Dados/Saida\"\n",
    "\n",
    "# Proporção do conjunto de treinamento\n",
    "train_ratio = 0.75\n",
    "\n",
    "# Proporção do conjunto de validação\n",
    "val_ratio = 0.1\n",
    "\n",
    "# Chamando a função split_dataset, ela separa o dataset em treino, teste e validação\n",
    "split_dataset(images_dir, coco_json_path, output_dir, train_ratio, val_ratio)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "object_detection_amb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
