{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pipeline de Detecção de Objetos usando GStreamer e DeepStream"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este notebook ensina como criar um pipeline de detecção de objetos utilizando GStreamer e o framework DeepStream da NVIDIA. O pipeline irá processar a entrada de vídeo de uma câmera usb, realizar a detecção de objetos com Deep Learning e exibir os resultados com sobreposições indicando o número e o tipo de objetos detectados.\n",
        "\n",
        "Ferramentas:\n",
        "\n",
        "- GStreamer: https://github.com/GStreamer/gstreamer\n",
        "- DeepStream: https://developer.nvidia.com/deepstream-sdk\n",
        "\n",
        "**OBS**: Para que seja feito em Python, é necessário compilar as bindings do DeepStream para Python. Esse link contém as intruções de como o fazer: https://github.com/NVIDIA-AI-IOT/deepstream_python_apps/tree/master/bindings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importação das bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importação de bibliotecas necessárias\n",
        "import os\n",
        "import sys\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "# Adicionando o caminho do módulo necessário ao sistema\n",
        "sys.path.append('../')\n",
        "\n",
        "# Importando as bibliotecas GStreamer\n",
        "import gi\n",
        "gi.require_version('Gst', '1.0')\n",
        "from gi.repository import GLib, Gst\n",
        "\n",
        "# Configurando o logging para informações detalhadas\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Importando outras bibliotecas necessárias\n",
        "import pandas as pd\n",
        "import pyds\n",
        "from common.is_aarch_64 import is_aarch64\n",
        "from common.bus_call import bus_call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variáveis Globais de Configuração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PGIE_FILE = os.environ.get('PGIE_CONFIG', './config_infer_primary_yoloV8.txt')\n",
        "WIDTH = os.environ.get('WIDTH', 1920)\n",
        "HEIGHT = os.environ.get('HEIGHT', 1080)\n",
        "FPS = os.environ.get('FPS', 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funções Auxiliares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Carregar o Arquivo de Configuração"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Esta função carrega o arquivo de configuração PGIE e extrai o caminho do arquivo de rótulos. O arquivo de configuração de inferência PGIE é necessário para informar ao pipeline quais são as configurações do modelo de deep learning que será utilizado para a detecção de objetos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_config_file(config_file_path):\n",
        "    \"\"\"\n",
        "    Carrega o arquivo de configuração PGIE e extrai o caminho do arquivo de rótulos.\n",
        "\n",
        "    Args:\n",
        "        config_file_path (str): Caminho para o arquivo de configuração PGIE.\n",
        "\n",
        "    Returns:\n",
        "        str: Caminho para o arquivo de rótulos.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: Se o caminho do arquivo de rótulos não for encontrado no arquivo de configuração.\n",
        "    \"\"\"\n",
        "    with open(config_file_path, 'r') as config_file:\n",
        "        lines = config_file.readlines()\n",
        "    for line in lines:\n",
        "        if 'labelfile-path=' in line:\n",
        "            return line.split('=')[1].strip()\n",
        "    raise ValueError(\"Caminho do arquivo de rótulos não encontrado no arquivo de configuração\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Carregar o Arquivo de Rótulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_label_file(label_file_path):\n",
        "    \"\"\"\n",
        "    Carrega os rótulos do arquivo de rótulos e cria um dicionário que mapeia nomes de classes para seus respectivos IDs.\n",
        "\n",
        "    Args:\n",
        "        label_file_path (str): Caminho para o arquivo de rótulos.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dicionário que mapeia nomes de classes para seus respectivos IDs.\n",
        "    \"\"\"\n",
        "    with open(label_file_path, 'r') as label_file:\n",
        "        lines = label_file.read().splitlines()\n",
        "    return {line: i for i, line in enumerate(lines)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Criação do Pipeline de Visão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A função `create_pipeline` é responsável por criar e configurar os elementos do pipeline GStreamer. Essa função inicializa todos os elementos necessários para o pipeline de processamento de vídeo e garante que todos os elementos sejam criados corretamente.\n",
        "\n",
        "#### Etapas da Função:\n",
        "1. **Criação do Pipeline**:\n",
        "   - Cria o objeto pipeline usando `Gst.Pipeline()`.\n",
        "   - Verifica se o pipeline foi criado com sucesso. Caso contrário, lança uma exceção `RuntimeError`.\n",
        "\n",
        "2. **Criação dos Elementos do Pipeline**:\n",
        "   - **Fonte de Vídeo (`v4l2src`)**: Elemento que captura vídeo de um dispositivo V4L2.\n",
        "   - **Filtro de Capacidades (`caps_v4l2src`)**: Filtro que define as capacidades do vídeo capturado.\n",
        "   - **Conversor de Vídeo (`vidconvsrc`)**: Elemento que converte o formato do vídeo.\n",
        "   - **Conversor de Vídeo NVidia (`nvvidconvsrc`)**: Elemento que converte o formato do vídeo para um formato compatível com NVMM.\n",
        "   - **Filtro de Capacidades NVMM (`caps_vidconvsrc`)**: Filtro que define as capacidades do vídeo na memória NVMM.\n",
        "   - **Muxer de Fluxo (`streammux`)**: Elemento que agrupa vários fluxos de entrada em um único fluxo de saída.\n",
        "   - **Inferenciador Primário (`pgie`)**: Elemento que realiza a inferência do modelo de deep learning.\n",
        "   - **Conversor de Vídeo NVidia (`nvvidconv`)**: Elemento que converte o formato do vídeo após a inferência.\n",
        "   - **Display On-Screen (`nvosd`)**: Elemento que exibe metadados, como caixas delimitadoras e texto, sobre o vídeo.\n",
        "   - **Sink de Vídeo (`sink`)**: Elemento que renderiza o vídeo. Dependendo da arquitetura, usa `nv3dsink` ou `nveglglessink`.\n",
        "\n",
        "3. **Verificação da Criação dos Elementos**:\n",
        "   - Itera sobre todos os elementos criados e verifica se cada elemento foi criado com sucesso.\n",
        "   - Se algum elemento não puder ser criado, lança uma exceção `RuntimeError` com o nome do elemento que falhou.\n",
        "\n",
        "4. **Retorno dos Elementos**:\n",
        "   - Retorna um dicionário contendo todos os elementos criados.\n",
        "\n",
        "#### Elementos Criados:\n",
        "- **pipeline**: Pipeline GStreamer.\n",
        "- **source**: Fonte de vídeo (`v4l2src`).\n",
        "- **caps_v4l2src**: Filtro de capacidades para a fonte de vídeo.\n",
        "- **vidconvsrc**: Conversor de vídeo.\n",
        "- **nvvidconvsrc**: Conversor de vídeo NVidia.\n",
        "- **caps_vidconvsrc**: Filtro de capacidades para NVMM.\n",
        "- **streammux**: Muxer de fluxo.\n",
        "- **pgie**: Inferenciador primário.\n",
        "- **nvvidconv**: Conversor de vídeo NVidia.\n",
        "- **nvosd**: Display on-screen.\n",
        "- **sink**: Sink de vídeo (`nv3dsink` ou `nveglglessink`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função para criar e configurar os elementos do pipeline\n",
        "\n",
        "def create_pipeline():\n",
        "    \"\"\"\n",
        "    Cria e configura o pipeline GStreamer e seus elementos.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dicionário contendo os elementos criados do GStreamer.\n",
        "\n",
        "    Raises:\n",
        "        RuntimeError: Se algum elemento do GStreamer não puder ser criado.\n",
        "    \"\"\"\n",
        "    pipeline = Gst.Pipeline()\n",
        "    if not pipeline:\n",
        "        raise RuntimeError(\"Não foi possível criar o Pipeline\")\n",
        "\n",
        "    source = Gst.ElementFactory.make(\"v4l2src\", \"usb-cam-source\")\n",
        "    caps_v4l2src = Gst.ElementFactory.make(\"capsfilter\", \"v4l2src_caps\")\n",
        "    vidconvsrc = Gst.ElementFactory.make(\"videoconvert\", \"convertor_src1\")\n",
        "    nvvidconvsrc = Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor_src2\")\n",
        "    caps_vidconvsrc = Gst.ElementFactory.make(\"capsfilter\", \"nvmm_caps\")\n",
        "    streammux = Gst.ElementFactory.make(\"nvstreammux\", \"Stream-muxer\")\n",
        "    pgie = Gst.ElementFactory.make(\"nvinfer\", \"primary-inference\")\n",
        "    nvvidconv = Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor\")\n",
        "    nvosd = Gst.ElementFactory.make(\"nvdsosd\", \"onscreendisplay\")\n",
        "    sink = Gst.ElementFactory.make(\"nv3dsink\" if is_aarch64() else \"nveglglessink\", \"nvvideo-renderer\")\n",
        "\n",
        "    elements = {\n",
        "        \"pipeline\": pipeline,\n",
        "        \"source\": source,\n",
        "        \"caps_v4l2src\": caps_v4l2src,\n",
        "        \"vidconvsrc\": vidconvsrc,\n",
        "        \"nvvidconvsrc\": nvvidconvsrc,\n",
        "        \"caps_vidconvsrc\": caps_vidconvsrc,\n",
        "        \"streammux\": streammux,\n",
        "        \"pgie\": pgie,\n",
        "        \"nvvidconv\": nvvidconv,\n",
        "        \"nvosd\": nvosd,\n",
        "        \"sink\": sink\n",
        "    }\n",
        "    \n",
        "    for name, element in elements.items():\n",
        "        if not element:\n",
        "            raise RuntimeError(f\"Não foi possível criar o {name}\")\n",
        "    \n",
        "    return elements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ligar os Elementos do Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Esta função liga os elementos do GStreamer dentro do pipeline, estabelecendo as conexões necessárias entre eles para o fluxo de dados funcionar corretamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função para ligar os elementos do pipeline\n",
        "\n",
        "def link_elements(elements):\n",
        "    \"\"\"\n",
        "    Liga os elementos do GStreamer dentro do pipeline.\n",
        "\n",
        "    Args:\n",
        "        elements (dict): Dicionário contendo os elementos do GStreamer.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    Raises:\n",
        "        RuntimeError: Se algum elemento não puder ser ligado.\n",
        "    \"\"\"\n",
        "    elements[\"pipeline\"].add(elements[\"source\"])\n",
        "    elements[\"pipeline\"].add(elements[\"caps_v4l2src\"])\n",
        "    elements[\"pipeline\"].add(elements[\"vidconvsrc\"])\n",
        "    elements[\"pipeline\"].add(elements[\"nvvidconvsrc\"])\n",
        "    elements[\"pipeline\"].add(elements[\"caps_vidconvsrc\"])\n",
        "    elements[\"pipeline\"].add(elements[\"streammux\"])\n",
        "    elements[\"pipeline\"].add(elements[\"pgie\"])\n",
        "    elements[\"pipeline\"].add(elements[\"nvvidconv\"])\n",
        "    elements[\"pipeline\"].add(elements[\"nvosd\"])\n",
        "    elements[\"pipeline\"].add(elements[\"sink\"])\n",
        "    \n",
        "    elements[\"source\"].link(elements[\"caps_v4l2src\"])\n",
        "    elements[\"caps_v4l2src\"].link(elements[\"vidconvsrc\"])\n",
        "    elements[\"vidconvsrc\"].link(elements[\"nvvidconvsrc\"])\n",
        "    elements[\"nvvidconvsrc\"].link(elements[\"caps_vidconvsrc\"])\n",
        "    \n",
        "    sinkpad = elements[\"streammux\"].get_request_pad(\"sink_0\")\n",
        "    srcpad = elements[\"caps_vidconvsrc\"].get_static_pad(\"src\")\n",
        "    \n",
        "    srcpad.link(sinkpad)\n",
        "    elements[\"streammux\"].link(elements[\"pgie\"])\n",
        "    elements[\"pgie\"].link(elements[\"nvvidconv\"])\n",
        "    elements[\"nvvidconv\"].link(elements[\"nvosd\"])\n",
        "    elements[\"nvosd\"].link(elements[\"sink\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configurar Propriedades dos Elementos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A função `set_element_properties` é responsável por configurar as propriedades dos elementos do GStreamer. Essa configuração é essencial para garantir que cada elemento no pipeline funcione corretamente de acordo com os requisitos do aplicativo.\n",
        "\n",
        "#### Etapas da Função:\n",
        "1. **Configuração do Elemento `caps_v4l2src`**:\n",
        "   - Define a propriedade `caps` para filtrar o formato de vídeo e a taxa de frames.\n",
        "   - Utiliza `Gst.Caps.from_string(f\"video/x-raw, framerate={FPS}/1\")` para definir as capacidades do vídeo cru com a taxa de frames especificada.\n",
        "\n",
        "2. **Configuração do Elemento `caps_vidconvsrc`**:\n",
        "   - Define a propriedade `caps` para filtrar o formato de vídeo na memória NVMM.\n",
        "   - Utiliza `Gst.Caps.from_string(\"video/x-raw(memory:NVMM)\")` para definir as capacidades de vídeo na memória NVMM.\n",
        "\n",
        "3. **Configuração do Elemento `source`**:\n",
        "   - Define a propriedade `device` para especificar o caminho do dispositivo V4L2 ( camera USB ).\n",
        "   - Utiliza `elements[\"source\"].set_property('device', device_path)` para definir o caminho do dispositivo.\n",
        "\n",
        "4. **Configuração do Elemento `streammux`**:\n",
        "   - Define várias propriedades do muxer de fluxo:\n",
        "     - `width`: Define a largura do fluxo de vídeo.\n",
        "     - `height`: Define a altura do fluxo de vídeo.\n",
        "     - `batch-size`: Define o tamanho do batch para processamento em batch.\n",
        "     - `batched-push-timeout`: Define o tempo limite para envio em batch.\n",
        "   - Utiliza `elements[\"streammux\"].set_property` para definir essas propriedades.\n",
        "\n",
        "5. **Configuração do Elemento `pgie`**:\n",
        "   - Define a propriedade `config-file-path` para especificar o caminho do arquivo de configuração do inferenciador primário.\n",
        "   - Utiliza `elements[\"pgie\"].set_property('config-file-path', PGIE_FILE)` para definir o caminho do arquivo de configuração.\n",
        "\n",
        "6. **Configuração do Elemento `sink`**:\n",
        "   - Define a propriedade `sync` para desativar a sincronização do vídeo.\n",
        "   - Utiliza `elements[\"sink\"].set_property('sync', False)` para definir essa propriedade.\n",
        "\n",
        "#### Propriedades Utilizadas:\n",
        "- **caps_v4l2src**:\n",
        "  - `caps`: Capacidades do vídeo cru com a taxa de frames especificada.\n",
        "  \n",
        "- **caps_vidconvsrc**:\n",
        "  - `caps`: Capacidades do vídeo na memória NVMM.\n",
        "  \n",
        "- **source**:\n",
        "  - `device`: Caminho do dispositivo V4L2.\n",
        "  \n",
        "- **streammux**:\n",
        "  - `width`: Largura do fluxo de vídeo.\n",
        "  - `height`: Altura do fluxo de vídeo.\n",
        "  - `batch-size`: Tamanho do batch para processamento.\n",
        "  - `batched-push-timeout`: Tempo limite para envio em batch.\n",
        "  \n",
        "- **pgie**:\n",
        "  - `config-file-path`: Caminho do arquivo PGIE.\n",
        "  \n",
        "- **sink**:\n",
        "  - `sync`: Desativa a sincronização do vídeo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_element_properties(elements, device_path):\n",
        "    \"\"\"\n",
        "    Configura as propriedades dos elementos do GStreamer.\n",
        "\n",
        "    Args:\n",
        "        elements (dict): Dicionário contendo os elementos do GStreamer.\n",
        "        device_path (str): Caminho para o dispositivo V4L2.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    elements[\"caps_v4l2src\"].set_property('caps', Gst.Caps.from_string(f\"video/x-raw, framerate={FPS}/1\"))\n",
        "    elements[\"caps_vidconvsrc\"].set_property('caps', Gst.Caps.from_string(\"video/x-raw(memory:NVMM)\"))\n",
        "    elements[\"source\"].set_property('device', device_path)\n",
        "    elements[\"streammux\"].set_property('width', WIDTH)\n",
        "    elements[\"streammux\"].set_property('height', HEIGHT)\n",
        "    elements[\"streammux\"].set_property('batch-size', 1)\n",
        "    elements[\"streammux\"].set_property('batched-push-timeout', 4000000)\n",
        "    elements[\"pgie\"].set_property('config-file-path', PGIE_FILE)\n",
        "    elements[\"sink\"].set_property('sync', False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Função de Probe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A função `osd_sink_pad_buffer_probe` é uma função de probe usada para lidar com a extração de metadados e atualizações de exibição. Esta função é chamada sempre que um buffer passa pelo pad ao qual a probe está anexada. \n",
        "\n",
        "#### Explicação da Função:\n",
        "1. **Carregamento do arquivo de rótulos**:\n",
        "   - A função começa carregando o caminho dos arquivos de configuração do modelo de DeepLeaning e parâmetros de video `load_config_file(PGIE_FILE)` e de anotações dos dados  `load_label_file(label_file_path)`.\n",
        "\n",
        "2. **Extração do buffer**:\n",
        "   - Obtém o buffer GStreamer (explicado abaixo) usando `info.get_buffer()`. Se o buffer não estiver presente, a função retorna `Gst.PadProbeReturn.OK`.\n",
        "\n",
        "3. **Extração de Metadados**:\n",
        "   - Usa `pyds.gst_buffer_get_nvds_batch_meta(hash(gst_buffer))` para obter os metadados do batch de imagens.\n",
        "   - Obtém a lista de metadados do frame usando `batch_meta.frame_meta_list`.\n",
        "\n",
        "4. **Processamento de Cada frame**:\n",
        "   - Itera sobre cada frame no batch.\n",
        "   - Usa `pyds.NvDsFrameMeta.cast(l_frame.data)` para converter os dados do frame em metadados do frame.\n",
        "   - Chama a função `process_frame` para processar os metadados do frame.\n",
        "   - Move para o próximo frame na lista.\n",
        "\n",
        "#### Metadados Utilizados:\n",
        "- **NvDsBatchMeta**: Metadados do batch que contêm informações sobre todos os frames processados em um único batch.\n",
        "- **NvDsFrameMeta**: Metadados do frame que contêm informações específicas sobre cada frame, incluindo número do frame, número de objetos detectados, e a lista de objetos.\n",
        "- **NvDsObjectMeta**: Metadados do objeto que contêm informações sobre cada objeto detectado, incluindo ID da classe do objeto e coordenadas da caixa delimitadora.\n",
        "\n",
        "#### Documentação Adicional:\n",
        "Para mais informações sobre os metadados utilizados no DeepStream, consulte a [documentação oficial da NVIDIA](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_metadata.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def osd_sink_pad_buffer_probe(pad, info, u_data):\n",
        "    \"\"\"\n",
        "    Função de probe para lidar com a extração de metadados e atualizações de exibição.\n",
        "\n",
        "    Args:\n",
        "        pad: O pad ao qual a probe está anexada.\n",
        "        info: Informações do buffer.\n",
        "        u_data: Dados do usuário (não utilizados).\n",
        "\n",
        "    Returns:\n",
        "        Gst.PadProbeReturn: Status da operação da probe.\n",
        "    \"\"\"\n",
        "    label_file_path = load_config_file(PGIE_FILE)\n",
        "    object_classes = load_label_file(label_file_path)\n",
        "    \n",
        "    gst_buffer = info.get_buffer()\n",
        "    if not gst_buffer:\n",
        "        return Gst.PadProbeReturn.OK\n",
        "    \n",
        "    batch_meta = pyds.gst_buffer_get_nvds_batch_meta(hash(gst_buffer))\n",
        "    l_frame = batch_meta.frame_meta_list\n",
        "    \n",
        "    # Processando cada frame no batch\n",
        "    while l_frame is not frame:\n",
        "        try:\n",
        "            frame_meta = pyds.NvDsFrameMeta.cast(l_frame.data)\n",
        "        except StopIteration:\n",
        "            break\n",
        "        \n",
        "        process_frame(frame_meta, object_classes, batch_meta)\n",
        "        \n",
        "        try:\n",
        "            l_frame = l_frame.next\n",
        "        except StopIteration:\n",
        "            break\n",
        "    \n",
        "    return Gst.PadProbeReturn.OK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Função para Processar cada Frame\n",
        "\n",
        "A função `process_frame` é responsável por processar cada frame, contando os objetos detectados e atualizando os metadados de exibição. Esta função é essencial para a contagem de objetos em cada frame e a exibição dessas informações na tela.\n",
        "\n",
        "#### Argumentos:\n",
        "- `frame_meta`: Metadados do frame.\n",
        "- `object_classes (dict)`: Dicionário que mapeia nomes de classes para IDs.\n",
        "- `batch_meta`: Metadados do batch.\n",
        "\n",
        "#### Retorno:\n",
        "- `None`\n",
        "\n",
        "#### Explicação da Função:\n",
        "1. **Inicialização do Contador de Objetos**:\n",
        "   - Cria um dicionário `obj_counter` para contar o número de objetos detectados para cada classe.\n",
        "\n",
        "2. **Extração de Informações do Frame**:\n",
        "   - Obtém o número do frame usando `frame_meta.frame_num`.\n",
        "   - Obtém o número de objetos detectados no frame usando `frame_meta.num_obj_meta`.\n",
        "   - Obtém a lista de metadados de objetos usando `frame_meta.obj_meta_list`.\n",
        "\n",
        "3. **Contagem dos Objetos Detectados**:\n",
        "   - Itera sobre a lista de objetos e conta quantos objetos de cada classe foram detectados.\n",
        "   - Usa `pyds.NvDsObjectMeta.cast(l_obj.data)` para converter os dados do objeto em metadados do objeto.\n",
        "   - Atualiza o contador de objetos `obj_counter`.\n",
        "\n",
        "4. **Criação e Configuração dos Metadados de Exibição**:\n",
        "   - Obtém a hora atual usando `datetime.now().strftime(\"%H:%M:%S\")`.\n",
        "   - Adquire um objeto de metadados de exibição usando `pyds.nvds_acquire_display_meta_from_pool(batch_meta)`.\n",
        "   - Define o número de rótulos de exibição (`display_meta.num_labels = 1`).\n",
        "   - Cria a string de texto de exibição que inclui o número do frame e o número de objetos detectados.\n",
        "\n",
        "5. **Adição de Informações de Contagem de Objetos à Exibição**:\n",
        "   - Itera sobre o dicionário `obj_counter` e adiciona a contagem de objetos de cada classe à string de texto de exibição.\n",
        "   - Configura os parâmetros de texto, como posição, fonte e cor do texto, e cor de fundo.\n",
        "\n",
        "6. **Adição dos Metadados de Exibição ao Frame**:\n",
        "   - Adiciona os metadados de exibição ao frame usando `pyds.nvds_add_display_meta_to_frame(frame_meta, display_meta)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_frame(frame_meta, object_classes, batch_meta):\n",
        "    \"\"\"\n",
        "    Processa cada frame, conta os objetos e atualiza os metadados de exibição.\n",
        "\n",
        "    Args:\n",
        "        frame_meta: Metadados do frame.\n",
        "        object_classes (dict): Dicionário que mapeia nomes de classes para IDs.\n",
        "        batch_meta: Metadados do batch.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    obj_counter = {id: 0 for _, id in object_classes.items()}\n",
        "    frame_number = frame_meta.frame_num\n",
        "    num_rects = frame_meta.num_obj_meta\n",
        "    l_obj = frame_meta.obj_meta_list\n",
        "\n",
        "    # Contando os objetos detectados no frame\n",
        "    while l_obj is not None:\n",
        "        try:\n",
        "            obj_meta = pyds.NvDsObjectMeta.cast(l_obj.data)\n",
        "        except StopIteration:\n",
        "            break\n",
        "        obj_counter[obj_meta.class_id] += 1\n",
        "        try:\n",
        "            l_obj = l_obj.next\n",
        "        except StopIteration:\n",
        "            break\n",
        "\n",
        "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
        "    display_meta = pyds.nvds_acquire_display_meta_from_pool(batch_meta)\n",
        "    display_meta.num_labels = 1\n",
        "    py_nvosd_text_params = display_meta.text_params[0]\n",
        "    display_txt = f\"Frame Number={frame_number} Number of Objects={num_rects}\"\n",
        "    \n",
        "    # Adicionando informações de contagem de objetos à exibição\n",
        "    for k, v in obj_counter.items():\n",
        "        _class = [cls for cls in object_classes.keys() if object_classes[cls] == k][0]\n",
        "        display_txt += f\" {_class}_count={v}\"\n",
        "    \n",
        "    py_nvosd_text_params.display_text = display_txt\n",
        "    py_nvosd_text_params.x_offset = 10\n",
        "    py_nvosd_text_params.y_offset = 12\n",
        "    py_nvosd_text_params.font_params.font_name = \"Serif\"\n",
        "    py_nvosd_text_params.font_params.font_size = 10\n",
        "    py_nvosd_text_params.font_params.font_color.set(1.0, 1.0, 1.0, 1.0)\n",
        "    py_nvosd_text_params.set_bg_clr = 1\n",
        "    py_nvosd_text_params.text_bg_clr.set(0.0, 0.0, 0.0, 1.0)\n",
        "    pyds.nvds_add_display_meta_to_frame(frame_meta, display_meta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Função Principal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Função Principal para Inicializar o Pipeline e o Loop de Eventos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Esta é a função principal que analisa os argumentos, configura o pipeline e inicia o loop de eventos. Ela inicializa o GStreamer, cria o loop de eventos GLib, configura o pipeline e o inicia, além de configurar o bus para receber mensagens de erro e estado do pipeline.\n",
        "\n",
        "### GStreamer:\n",
        "- **Biblioteca multimídia**: GStreamer é uma biblioteca que permite a construção de gráficos de fluxo de mídia complexos.\n",
        "- **Elementos e plugins**: Utiliza uma variedade de elementos (plugins) que podem ser conectados para formar pipelines de processamento de mídia.\n",
        "- **Flexibilidade**: Suporta diferentes tipos de mídia e pode ser utilizado para processamento de áudio e vídeo em tempo real ou offline.\n",
        "\n",
        "### GLib:\n",
        "- **Fundação para GTK+**: GLib é a biblioteca base usada pelo GTK+, mas também pode ser utilizada de forma independente.\n",
        "- **Utilidades de sistema**: Fornece funções para manipulação de estruturas de dados, utilidades portáveis de entrada/saída e interfaces para threads.\n",
        "- **Loop de eventos**: GLib Main Loop é uma implementação de loop de eventos que permite a integração de diferentes fontes de eventos (como timers e I/O) em um único loop.\n",
        "\n",
        "### GTK:\n",
        "- **Biblioteca de interface gráfica**: GTK (GIMP Toolkit) é uma biblioteca para criar interfaces gráficas de usuário (GUI) de maneira multiplataforma.\n",
        "- **Aplicações**: Utilizada para desenvolver uma variedade de aplicações gráficas, desde simples utilitários até softwares complexos.\n",
        "- **Integração com GLib**: Baseada na GLib, fornece uma coleção de widgets (como botões, janelas, sliders) para facilitar o desenvolvimento de interfaces gráficas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main(args):\n",
        "    \"\"\"\n",
        "    Função principal para analisar argumentos, configurar o pipeline e iniciar o loop de eventos.\n",
        "\n",
        "    Args:\n",
        "        args (list): Argumentos da linha de comando.\n",
        "\n",
        "    Returns:\n",
        "        int: Status de saída.\n",
        "    \"\"\"\n",
        "\n",
        "    Gst.init(None)\n",
        "    loop = GLib.MainLoop()\n",
        "    \n",
        "    # Caminho do dispositivo de vídeo (padrão: /dev/video0)\n",
        "    device_path = \"/dev/video0\" if len(args) < 2 else args[1]\n",
        "    elements = create_pipeline()\n",
        "    link_elements(elements)\n",
        "    set_element_properties(elements, device_path)\n",
        "    \n",
        "    # Configurando o bus para receber mensagens\n",
        "    bus = elements[\"pipeline\"].get_bus()\n",
        "    bus.add_signal_watch()\n",
        "    bus.connect(\"message\", bus_call, loop)\n",
        "    \n",
        "    # Adicionando a função de probe ao pad do OSD\n",
        "    osdsinkpad = elements[\"nvosd\"].get_static_pad(\"sink\")\n",
        "    osdsinkpad.add_probe(Gst.PadProbeType.BUFFER, osd_sink_pad_buffer_probe, 0)\n",
        "    \n",
        "    logger.info(\"Iniciando o pipeline\")\n",
        "    elements[\"pipeline\"].set_state(Gst.State.PLAYING)\n",
        "    \n",
        "    try:\n",
        "        loop.run()\n",
        "    except:\n",
        "        pass\n",
        "    finally:\n",
        "        elements[\"pipeline\"].set_state(Gst.State.NULL)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sys.exit(main(sys.argv))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
