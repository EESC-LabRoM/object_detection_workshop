{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import logging\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def convert_coco_to_yolo(size, box):\n",
    "    \"\"\"\n",
    "    Convert COCO bounding box format to YOLO format.\n",
    "    size: (width, height) of the image\n",
    "    box: [x_top_left, y_top_left, width, height] COCO bbox\n",
    "    \"\"\"\n",
    "    dw = 1. / size[0]\n",
    "    dh = 1. / size[1]\n",
    "    x = (box[0] + box[2] / 2.0) * dw\n",
    "    y = (box[1] + box[3] / 2.0) * dh\n",
    "    w = box[2] * dw\n",
    "    h = box[3] * dh\n",
    "    return (x, y, w, h)\n",
    "\n",
    "def process_annotations(dataset_path):\n",
    "    \"\"\"\n",
    "    Process COCO annotations and convert them to YOLO format.\n",
    "    \"\"\"\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        label_path = Path(dataset_path) / \"labels\" / split / 'coco.json'\n",
    "        if not label_path.exists():\n",
    "            logger.warning(f\"File not found: {label_path}\")\n",
    "            continue\n",
    "\n",
    "        with open(label_path) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Mapping from image id to filename\n",
    "        image_info = {img['id']: img for img in data['images']}\n",
    "        \n",
    "        # Process each annotation\n",
    "        for ann in data['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            coco_bbox = ann['bbox']\n",
    "            category_id = ann['category_id'] - 1  # Assuming category IDs are 1-indexed in COCO\n",
    "            img_filename = Path(image_info[img_id]['file_name'])\n",
    "            img_size = (image_info[img_id]['width'], image_info[img_id]['height'])\n",
    "            yolo_bbox = convert_coco_to_yolo(img_size, coco_bbox)\n",
    "            \n",
    "            txt_path = label_path.parent / (img_filename.stem + '.txt')\n",
    "            with open(txt_path, 'a') as file:\n",
    "                file.write(f\"{category_id} {' '.join(map(str, yolo_bbox))}\\n\")\n",
    "            logger.info(f\"Processed annotation for image: {img_filename}\")\n",
    "\n",
    "def create_yaml_file(dataset_path):\n",
    "    \"\"\"\n",
    "    Create a .yml file for the dataset configuration using class names extracted from coco.json.\n",
    "    \"\"\"\n",
    "    label_path = dataset_path / \"labels\" / 'train' / 'coco.json'\n",
    "    if not label_path.exists():\n",
    "        logger.error(f\"File not found: {label_path}\")\n",
    "        return\n",
    "\n",
    "    with open(label_path) as f:\n",
    "        data = json.load(f)\n",
    "    class_names = {category['id'] - 1: category['name'] for category in data['categories']}\n",
    "\n",
    "    # Ensure the classes are sorted by their ids and formatted correctly\n",
    "    sorted_class_names = sorted(class_names.items())\n",
    "    class_entries = \"\\n\".join([f\"  {id}: {name}\" for id, name in sorted_class_names])\n",
    "\n",
    "    yaml_content = f\"\"\"path: {dataset_path.absolute()}  # dataset root dir\n",
    "train: images/train  # train images (relative to 'path')\n",
    "val: images/val  # val images (relative to 'path')\n",
    "test:  # test images (optional)\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "{class_entries}\n",
    "    \"\"\"\n",
    "\n",
    "    yaml_path = dataset_path / 'data.yaml'\n",
    "    with open(yaml_path, 'w') as file:\n",
    "        file.write(yaml_content.strip())\n",
    "    logger.info(f\"YAML file created at {yaml_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Process COCO annotations and create YOLO dataset.\")\n",
    "    parser.add_argument(\"dataset_path\", help=\"Path to the root directory of the dataset.\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    dataset_root = Path(args.dataset_path)\n",
    "    \n",
    "    process_annotations(dataset_root)\n",
    "    create_yaml_file(dataset_root)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
